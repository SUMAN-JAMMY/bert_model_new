# -*- coding: utf-8 -*-
"""Cleaned_BERT_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12BEZqR2SEAg0I2qkxWXSgJHaWFUeclhZ
"""

!pip install transformers datasets torch scikit-learn

import torch
import pandas as pd
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from datasets import Dataset
import random

def create_sample_data(num_samples=1000):
    positive_reviews = [
        "Professor Smith is an excellent teacher who explains concepts clearly.",
        "Amazing instructor, very helpful during office hours.",
        "The best teacher I've had in college, highly recommend.",
        "Clear explanations and fair grading system.",
        "Engaging lectures that make the material interesting.",
    ]

    negative_reviews = [
        "Terrible teacher, doesn't explain anything clearly.",
        "Avoid this professor if possible, very unhelpful.",
        "The worst instructor I've ever had.",
        "Unclear expectations and unfair grading.",
        "Boring lectures that put everyone to sleep.",
    ]

    reviews, labels = [], []
    for _ in range(num_samples // 2):
        reviews.append(random.choice(positive_reviews))
        labels.append(1)
    for _ in range(num_samples // 2):
        reviews.append(random.choice(negative_reviews))
        labels.append(0)

    return pd.DataFrame({'text': reviews, 'label': labels})

df = create_sample_data(800)

train_texts, temp_texts, train_labels, temp_labels = train_test_split(
    df['text'].tolist(),
    df['label'].tolist(),
    test_size=0.3,
    random_state=42,
    stratify=df['label']
)

val_texts, test_texts, val_labels, test_labels = train_test_split(
    temp_texts,
    temp_labels,
    test_size=0.5,
    random_state=42,
    stratify=temp_labels
)

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_function(examples):
    return tokenizer(
        examples['text'],
        padding="max_length",
        truncation=True,
        max_length=128
    )

train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels}).map(tokenize_function, batched=True)
val_dataset   = Dataset.from_dict({'text': val_texts,   'label': val_labels}).map(tokenize_function, batched=True)
test_dataset  = Dataset.from_dict({'text': test_texts,  'label': test_labels}).map(tokenize_function, batched=True)

train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

model = BertForSequenceClassification.from_pretrained(
    'bert-base-uncased',
    num_labels=2
)

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=2,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    logging_dir='./logs',
    logging_steps=10,
)

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    acc = accuracy_score(labels, preds)
    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics
)

trainer.train()

model.save_pretrained("./teacher_review_model")
tokenizer.save_pretrained("./teacher_review_model")

def predict_sentiment(text):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128).to(device)

    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)

    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    predicted_class = torch.argmax(probs, dim=1).item()
    confidence = probs[0][predicted_class].item()

    sentiment = "Positive" if predicted_class == 1 else "Negative"
    return {"sentiment": sentiment, "confidence": confidence}

print(predict_sentiment(" what the fuck the teacher taught i couldn't understand it "))

